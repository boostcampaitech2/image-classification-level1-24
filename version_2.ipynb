{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Model: EfficientNet-b7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import multiprocessing as mp\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize, GaussianBlur, RandomRotation, ColorJitter\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import dataset_hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "def send_message_to_slack(text):\n",
    "    url = \"WebHook Url\"\n",
    "    payload = { \"text\" : text }\n",
    "    requests.post('', json=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "import random\n",
    "SEED = 2021\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)  # type: ignore\n",
    "torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation - 우선은 없이 해봄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RGB별 평균, 표준편차 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_mean_std(path):\n",
    "    \"\"\"\n",
    "    RGB 평균 및 표준편차를 수집하는 함수입니다.\n",
    "    Args:\n",
    "        path: path_add_label.csv의 위치\n",
    "    Returns:\n",
    "        mean, std\n",
    "    \"\"\"\n",
    "    img_info = dict(means=[], stds=[])\n",
    "    path_label = pd.read_csv(path)\n",
    "    for img_path in path_label['path']:\n",
    "        img = np.array(Image.open(os.path.join('./train/train/images',img_path)))\n",
    "        # (0,1,2)중 0번과 1번에 대해 평균\n",
    "        # 512, 384 에 대한 평균이 3장 나옴\n",
    "        img_info['means'].append(img.mean(axis=(0,1)))\n",
    "        img_info['stds'].append(img.std(axis=(0,1)))\n",
    "            \n",
    "    return np.mean(img_info[\"means\"], axis=0) / 255., np.mean(img_info[\"stds\"], axis=0) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std  = np.array([0.56019358, 0.52410121, 0.501457  ]), np.array([0.23318603, 0.24300033, 0.24567522])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDataset(data.Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        img_dir: 학습 이미지 폴더(images)의 root directory(./train/train/images)\n",
    "        transforms안넣으면 totensor변환만 해서 내보냄\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        self.img_dir = img_dir\n",
    "        self.path = []\n",
    "        self.label = []\n",
    "        self.class_num = 18\n",
    "        self.setup()\n",
    "\n",
    "    \n",
    "    def setup(self):\n",
    "        filenames = os.listdir(self.img_dir)\n",
    "        for i in filenames:\n",
    "            if not i.startswith(\"._\"):\n",
    "                img_name = os.listdir(os.path.join(self.img_dir, i))\n",
    "                for j in img_name:\n",
    "                    if not j.startswith('._'):\n",
    "                        self.path.append(i+'/'+j)\n",
    "                        gender = 0 if i.split('_')[1] == 'male' else 1\n",
    "                        age = int(i.split('_')[3])\n",
    "                        age_range = 0 if age < 30 else 1 if age < 60 else 2\n",
    "                        if 'incorrect' in j:\n",
    "                            mask = 1\n",
    "                        elif 'mask' in j:\n",
    "                            mask=0\n",
    "                        elif 'normal' in j:\n",
    "                            mask=2\n",
    "                        self.label.append(mask * 6 + gender * 3 + age_range)\n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        y = self.label[index]\n",
    "        img_path = self.path[index]\n",
    "    \n",
    "        img = Image.open(os.path.join(self.img_dir,img_path))\n",
    "        if self.transform != None:\n",
    "            X = self.transform(img)\n",
    "        else:\n",
    "            tt = transforms.ToTensor()\n",
    "            X = tt(img)\n",
    "        return X, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정의한 Augmentation 함수와 Dataset 클래스 객체를 생성합니다.\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        Resize((int(512 / 2), int(384/ 2))),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "dataset = MaskDataset(\n",
    "    img_dir = '/opt/ml/input/data/train/images',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# train dataset과 validation dataset을 8:2 비율로 나눕니다.\n",
    "n_val = int(len(dataset) * 0.2)\n",
    "n_train = len(dataset) - n_val\n",
    "train_dataset, val_dataset = data.random_split(dataset, [n_train, n_val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataloader은 데이터를 섞어주어야 합니다. (shuffle=True)\n",
    "train_loader = data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=4, \n",
    "#     cuda설정이안돼서 num_workers 설정하면 안돌아감\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=4,\n",
    "    shuffle=False\n",
    ")\n",
    "loader={'train':train_loader,\n",
    "       'val':val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images shape: torch.Size([16, 3, 256, 192])\n",
      "labels shape: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(f'images shape: {images.shape}')\n",
    "print(f'labels shape: {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n",
      "네트워크 필요 입력 채널 개수 3\n",
      "네트워크 출력 채널 개수 (예측 class type 개수) 18\n"
     ]
    }
   ],
   "source": [
    "vision_model = EfficientNet.from_pretrained('efficientnet-b7', num_classes=18)\n",
    "print(\"네트워크 필요 입력 채널 개수\", vision_model._conv_stem.weight.shape[1])\n",
    "print(\"네트워크 출력 채널 개수 (예측 class type 개수)\", vision_model._fc.weight.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0121, -0.0100,  0.0074,  0.0148, -0.0026,  0.0135,  0.0026, -0.0176,\n",
       "        -0.0142, -0.0017,  0.0163, -0.0195,  0.0001, -0.0046,  0.0185,  0.0179,\n",
       "        -0.0107,  0.0187])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight및 bias 초기화\n",
    "torch.nn.init.xavier_uniform_(vision_model._fc.weight)\n",
    "stdv = 1. / math.sqrt(vision_model._fc.weight.size(1))\n",
    "vision_model._fc.bias.data.uniform_(-stdv, stdv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 필요한 설정\n",
    "vision_model.to(device)\n",
    "LEARNING_RATE = 0.0001 \n",
    "NUM_EPOCH = 10\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(vision_model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_accuracy = 0.\n",
    "best_val_loss = 9999.\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        n_iter = 0\n",
    "        epoch_f1 = 0\n",
    "        if  phase == \"val\":\n",
    "            confusion_matrix = np.zeros((18, 18))\n",
    "\n",
    "        if phase == \"train\":\n",
    "            vision_model.train()\n",
    "        elif phase == \"val\":\n",
    "            vision_model.eval()\n",
    "\n",
    "        for ind, (images, labels) in enumerate(tqdm(loader[phase])):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad() # parameter gradient를 업데이트 전 초기화함\n",
    "\n",
    "            with torch.set_grad_enabled(phase == \"train\"): # train 모드일 시에는 gradient를 계산\n",
    "                logits = vision_model(images)\n",
    "                _, preds = torch.max(logits, 1)\n",
    "                loss = loss_fn(logits, labels)\n",
    "\n",
    "                if phase == \"train\":\n",
    "                    loss.backward() \n",
    "                    optimizer.step()\n",
    "            # Metrics 계산 부분 ==============================================================================\n",
    "            epoch_f1 += f1_score(labels.cpu().numpy(), preds.cpu().numpy(), average='macro')\n",
    "            n_iter += 1\n",
    "            if  phase == \"val\":\n",
    "                for t, p in zip(labels.view(-1), preds.view(-1)): # confusion matrix에 값 입력, 언제가 최적일 지 몰라 매 epoch돌아감\n",
    "                    confusion_matrix[t.long(), p.long()] += 1    \n",
    "            running_loss += loss.item() * images.size(0) # 한 Batch에서의 loss 값, images.size(0) = batch size\n",
    "            running_acc += torch.sum(preds == labels.data) # 한 Batch에서의 Accuracy 값\n",
    "            \n",
    "            \n",
    "    # 한 epoch이 모두 종료되었을 때,\n",
    "    epoch_loss = running_loss / len(loader[phase].dataset)\n",
    "    epoch_acc = running_acc / len(loader[phase].dataset)\n",
    "    epoch_f1 = epoch_f1/n_iter\n",
    "\n",
    "    print(f\"epoch-{epoch}의 {phase}-데이터 평균 Loss : {epoch_loss:.3f}, 평균 Accuracy : {epoch_acc:.3f}, 평균 f1:{epoch_f1}\")\n",
    "    if phase == \"val\" and best_val_accuracy < epoch_acc: \n",
    "        best_val_accuracy = epoch_acc\n",
    "    if phase == \"val\" and best_val_loss > epoch_loss: \n",
    "        best_val_loss = epoch_loss\n",
    "print(\"학습 종료!\")\n",
    "print(f\"최고 accuracy : {best_val_accuracy:3f}, 최고 낮은 loss : {best_val_loss:3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일을 저장\n",
    "from pytz import timezone\n",
    "import datetime as dt\n",
    "\n",
    "now = (dt.datetime.now().astimezone(timezone(\"Asia/Seoul\")).strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "torch.save(vision_model,f\"save_model/{now}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_message_to_slack(f\"학습 완료 되었습니다.{now}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "class_names=[str(i) for i in range(18)]\n",
    "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
    "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap='YlGnBu')\n",
    "\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f'save_model/{now}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    \"\"\"\n",
    "    img_paths: image위치가 들어있는 주소 리스트\n",
    "    \"\"\"\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/opt/ml/input/data/eval'\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            Resize((int(512 / 2), int(384/ 2))),\n",
    "            ToTensor(),\n",
    "            Normalize(mean=mean, std=std),\n",
    "        ])\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(f'submission/submission_5.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
